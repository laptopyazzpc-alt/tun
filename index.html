<!DOCTYPE html>
<html lang="id">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Gesture + Efek Darah</title>
<style>
  body { margin: 0; overflow: hidden; background: #000; display: flex; justify-content: center; align-items: center; height: 100vh; }
  canvas { position: absolute; top: 0; left: 0; }
  video { display: none; }
  #startBtn {
    position: absolute;
    z-index: 10;
    padding: 10px 20px;
    font-size: 18px;
    cursor: pointer;
  }
</style>
</head>
<body>
<button id="startBtn">Start</button>
<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

<script>
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
let lastSpeechTime = 0;
const cooldown = 2000; // 2 detik
const startBtn = document.getElementById('startBtn');

// Inisialisasi Web Speech API
const synth = window.speechSynthesis;
function speak(text){
    if(!synth.speaking){
        const utter = new SpeechSynthesisUtterance(text);
        synth.speak(utter);
    }
}

// Start button event
startBtn.addEventListener('click', async () => {
    // Mulai kamera
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    video.srcObject = stream;

    // Set canvas size saat video siap
    video.addEventListener('loadeddata', () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        detectHands();
        speak("Sistem siap!");
        startBtn.style.display = 'none';
    });
});

// Inisialisasi MediaPipe Hands
const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
hands.setOptions({
    maxNumHands: 2,
    modelComplexity: 1,
    minDetectionConfidence: 0.7,
    minTrackingConfidence: 0.7
});

// Hasil deteksi
hands.onResults(results => {
    ctx.clearRect(0,0,canvas.width,canvas.height);
    if(video.readyState >= 2){
        ctx.drawImage(video,0,0,canvas.width,canvas.height);
    }

    if(results.multiHandLandmarks && results.multiHandedness){
        results.multiHandLandmarks.forEach((landmarks, index) => {
            // ðŸ”¹ Garis merah antar sendi tangan
            for(let i=0;i<landmarks.length-1;i++){
                const x1 = landmarks[i].x*canvas.width;
                const y1 = landmarks[i].y*canvas.height;
                const x2 = landmarks[i+1].x*canvas.width;
                const y2 = landmarks[i+1].y*canvas.height;
                ctx.strokeStyle = "red";
                ctx.lineWidth = 2;
                ctx.beginPath();
                ctx.moveTo(x1,y1);
                ctx.lineTo(x2,y2);
                ctx.stroke();
            }

            // ðŸ”¹ Gesture detection
            const handLabel = results.multiHandedness[index].label; // "Left" / "Right"
            const fingers = landmarks.map((lm,i) => {
                if([4,8,12,16,20].includes(i)) return landmarks[i].y < landmarks[i-2].y ? 1 : 0;
                return 0;
            });

            const now = Date.now();
            if(now - lastSpeechTime > cooldown){
                if(handLabel === "Right" && JSON.stringify(fingers.slice(0,5)) === "[0,1,0,0,0]"){
                    speak("Nama saya");
                    lastSpeechTime = now;
                } 
                else if(handLabel === "Left" && JSON.stringify(fingers.slice(0,5)) === "[1,1,1,1,1]"){
                    speak("Bara");
                    lastSpeechTime = now;
                } 
                else if(handLabel === "Right" && JSON.stringify(fingers.slice(0,5)) === "[0,1,1,0,0]"){
                    speak("Sampai jumpa");
                    lastSpeechTime = now;
                }
            }
        });
    }
});

// Looping frame
async function detectHands(){
    if(video.readyState >= 2){
        await hands.send({image: video});
    }
    requestAnimationFrame(detectHands);
}
</script>
</body>
</html>
