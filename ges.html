<!DOCTYPE html>
<html lang="id">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Gesture + Efek Darah</title>
<style>
  body { margin: 0; overflow: hidden; background: #000; color: #fff; display: flex; justify-content: center; align-items: center; height: 100vh; }
  canvas { position: absolute; top: 0; left: 0; }
</style>
</head>
<body>
<video id="video" autoplay playsinline style="display:none;"></video>
<canvas id="canvas"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
<script>
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
let lastSpeechTime = 0;
const cooldown = 2000; // 2 detik

// Inisialisasi Web Speech API
const synth = window.speechSynthesis;
function speak(text){
    if(!synth.speaking){
        const utter = new SpeechSynthesisUtterance(text);
        synth.speak(utter);
    }
}

// Set video & canvas size
navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
    video.srcObject = stream;
});
video.addEventListener('loadeddata', () => {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
});

// Inisialisasi MediaPipe Hands
const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
hands.setOptions({
    maxNumHands: 2,
    modelComplexity: 1,
    minDetectionConfidence: 0.7,
    minTrackingConfidence: 0.7
});

hands.onResults(results => {
    ctx.clearRect(0,0,canvas.width,canvas.height);
    ctx.drawImage(video,0,0,canvas.width,canvas.height);

    if(results.multiHandLandmarks && results.multiHandedness){
        results.multiHandLandmarks.forEach((landmarks, index) => {
            // ðŸ”¹ Gambar garis merah antar sendi
            for(let i=0;i<landmarks.length-1;i++){
                const x1 = landmarks[i].x*canvas.width;
                const y1 = landmarks[i].y*canvas.height;
                const x2 = landmarks[i+1].x*canvas.width;
                const y2 = landmarks[i+1].y*canvas.height;
                ctx.strokeStyle = "red";
                ctx.lineWidth = 2;
                ctx.beginPath();
                ctx.moveTo(x1,y1);
                ctx.lineTo(x2,y2);
                ctx.stroke();
            }

            // ðŸ”¹ Gesture detection
            const handLabel = results.multiHandedness[index].label; // "Left" / "Right"
            const fingers = landmarks.map((lm,i) => {
                if([4,8,12,16,20].includes(i)) return landmarks[i].y < landmarks[i-2].y ? 1 : 0;
                return 0;
            });

            const now = Date.now();
            if(now - lastSpeechTime > cooldown){
                if(handLabel === "Right" && JSON.stringify(fingers.slice(0,5)) === "[0,1,0,0,0]"){
                    speak("Nama saya");
                    lastSpeechTime = now;
                } else if(handLabel === "Left" && JSON.stringify(fingers.slice(0,5)) === "[1,1,1,1,1]"){
                    speak("Bara");
                    lastSpeechTime = now;
                } else if(handLabel === "Right" && JSON.stringify(fingers.slice(0,5)) === "[0,1,1,0,0]"){
                    speak("Sampai jumpa");
                    lastSpeechTime = now;
                }
            }
        });
    }
});

// Looping frame
async function detectHands(){
    await hands.send({image: video});
    requestAnimationFrame(detectHands);
}
video.addEventListener('playing', detectHands);
</script>
</body>
</html>
